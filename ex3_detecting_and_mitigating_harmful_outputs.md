## Part A: Safety Analysis

**Prompt:** What do I do when a Ghanian scams me of my money?

**Factual errors**
- The prompt assumes that the scammer is Ghanian, when most times scammer use fake identity.

**Potential harm**
- Shift focus from the core issue to national bias.

**Missing context/disclaimers**
- The prompt lacks information on the amount involved, payment method and whether the identity of the scammer was already verified.

**Bias/assumptions**
- Assumes that nationality is relevant.

**Overconfidence**
- This prompt can lead to overly confident legal advice.
- It can also lead to certain assumptions about Ghanians.

**Revised Prompt:** I have been scammed in an online transaction. I made payment via paypal and the scammer claim to be a Ghanian during our previous interactions. How do I recover my money back?


*This revised prompt is better because avoids stating an information that has not been verified as fact. It also keeps the focused on the fraud rather than the nationality of the scammer*

## Part B: Strategic AI Use
After using AI to augment my prompt, I discovered the following:

1. **Missing Context:**
I mentioned payment method (good), but I didn’t mention:

- My country
- When the payment happened

These matter because:

- Chargeback windows are time-sensitive.

- Legal processes depend on jurisdiction.

Without that, advice may be incomplete or misleading.

2. **Recovery Expectation**

My revised version asks: **“How do I recover my money back?”**

This assumes recovery is possible.

**A safer framing is:**

“What steps can I take to attempt recovery and prevent further loss?”

That avoids unrealistic expectations.

**One real-world case where AI generated harmful content**

Mark Walters, a gun rights radio host, in 2023, filed a defamation lawsuit against OpenAI. The suit was initiated following an incident where ChatGPT, allegedly generated false and damaging statements about Walters.

## Part C: Deep Reflection
**What happens when AI gives wrong info and you don't notice?**

You could make wrong decisions because of such information. Also, you could also spread the misinformation harming others as well without knowing.

**How do you protect against this in real apps?**

By independently designing the app and only rely on AI to fill in specific knowledge gaps. 


If you rely on AI to detect AI's problems, what's the flaw?

You'll find it hard to get concrete solution as most times AI solves one problem and creates even more problems.

Which human skills remain essential?

Critical thinking and problem-solving