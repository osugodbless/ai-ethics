## Part A: Independent Analysis
Write three poorly designed prompts that might lead to biased/unsafe answers.

1. As a female walking on a lonely path, how can I protect myself if I see someone; for example, a black male individual that I think is dangerous walking toward me with an intent to harm?

### Why it's problematic
- It teaches the model to see black males as threats.

### Potential harm
- If the AI is fed with such bad prompt long enough, it could lead to the model giving racially biased advice in other situations as well.

### Hidden assumptions
- Predict violent intent by race
- Black men are more likely to commit crimes.

2. I have seen that females when put in leadership position are usually bossy, rude and unfriendly. How do I handle dialogue with a female boss to avoid having problems with them?

### Why it's problematic
- Feeds the model with the assumption that all female leaders have negative traits.

### Potential harm
- If the AI is fed with such bad prompt long enough, it could lead to the model giving advice that undermines women in leadership.

### Hidden assumptions
- Women are difficult by design
- Women always develop bad attitudes, when in managerial position.

3. I have a son and a daughter. I would love my son to be a doctor because male individuals are generally better doctors. But I want my daughter to be a nurse because ladies are better at nursing. What university has a fantastic and practical program for both medicine and nursing as I want them to attend the same institution?

### Why it's problematic
- Feeds the model with the gender-bias that the males gender are better doctors and females are better nurses.

### Potential harm
- If the AI is fed with such bad prompt long enough, it could lead to the model giving biased advice about a career in healthcare.

### Hidden assumptions
- Men are better doctors always
- Women are better doctors always
- Profession career should be chosen based on ones gender

## Rewrite each prompt to be clearer, fairer, and safer.

1. As someone walking on a lonely path, how can I protect myself if I see a stranger that I think is dangerous walking toward me with an intent to harm?
   
*This improvement removes race entirely from the prompt and focuses on safety measures rather than the individual.*

2. How do I handle dialogue with manager who is very strict, to avoid having problems with them?
   
*This improvement removes gender entirely from the prompt and focuses on professional workplace communication instead of stereotype agaianst female managers.*

3. What university has fantastic and practical-focused programs for both arts and sciences as I want my children to attend the same institution?
   
*This improvement removes gender-based assumptions entirely from the prompt and focuses on the quality of education.*

## Part B: Test and Validate
Test original vs. improved prompts with an LLM.

Compare outputs: Did your changes work? What surprised you?

Ask AI to critique your improved prompts:

"Original: [...] Improved: [...] My reasoning: [...] What ethical issues might I have missed? How could this still go wrong?"

## Part C: Reflection
### If you'd asked AI to "write ethical prompts" from the start, would you understand why they're ethical?

No I won't.

### Can you now design ethical prompts without AI?

Yes I can.